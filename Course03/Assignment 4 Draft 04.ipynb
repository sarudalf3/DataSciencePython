{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUCROC for random forests\n",
      "0.8943301874402421\n",
      "(61001,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "284932    0.034946\n",
       "285362    0.009513\n",
       "285361    0.043883\n",
       "285338    0.045139\n",
       "285346    0.045055\n",
       "            ...   \n",
       "376496    0.026914\n",
       "376497    0.026914\n",
       "376499    0.041623\n",
       "376500    0.041623\n",
       "369851    0.041815\n",
       "Name: compliance, Length: 61001, dtype: float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    #Insert lat and lon in address embbeded in adresses csv \n",
    "add = pd.read_csv('addresses.csv') \n",
    "lat = pd.read_csv('latlons.csv') \n",
    "geoRef = pd.merge(add,lat, how='left', on='address')\n",
    "geoRef.set_index(['ticket_id'], inplace=True)\n",
    "geoRef=geoRef[['lat','lon']]\n",
    "\n",
    "train = pd.read_csv('train.csv', sep=',', encoding='cp1252', low_memory=False,\n",
    "                    parse_dates = ['ticket_issued_date', 'hearing_date'], index_col='ticket_id')\n",
    "train = pd.merge(train, geoRef, how='left', left_index=True, right_index=True)\n",
    "\n",
    "test = pd.read_csv('test.csv', sep=',', encoding='cp1252', low_memory=False,\n",
    "                    parse_dates = ['ticket_issued_date', 'hearing_date'], index_col='ticket_id')\n",
    "test = pd.merge(test, geoRef, how='left', left_index=True, right_index=True)\n",
    "\n",
    "train = train.dropna(subset=['compliance']) #drop compliance nan\n",
    "train = train[train['agency_name'] != 'Neighborhood City Halls'] #delete option\n",
    "#disposition feature (replace)\n",
    "disposition_replace = {'Responsible by Default': 'By default',\n",
    "                       'Responsible by Determination': 'By determination',\n",
    "                       'Responsible (Fine Waived) by Admis': 'Fine Waived',\n",
    "                       'Responsible (Fine Waived) by Deter': 'Fine Waived',\n",
    "                       'Responsible - Compl/Adj by Default': 'By default',\n",
    "                       'Responsible - Compl/Adj by Determi': 'By determination',\n",
    "                       'Responsible by Admission': 'By admission',\n",
    "                       'Responsible by Dismissal': 'By default'}\n",
    "train.disposition.replace(disposition_replace, inplace=True)\n",
    "test.disposition.replace(disposition_replace, inplace=True)\n",
    "#discount feature (1 has discount, 0 without discount)\n",
    "train['discount'] = train.discount_amount.apply(lambda x:1 if x > 0 else 0)\n",
    "test['discount'] = test.discount_amount.apply(lambda x:1 if x > 0 else 0)\n",
    "#bins judgement amount\n",
    "cut = [-1, 100, 150, 300, float(\"inf\")]\n",
    "train['judgment_level'] = pd.cut(train.judgment_amount, bins=cut)\n",
    "test['judgment_level'] = pd.cut(test.judgment_amount, bins=cut)\n",
    "#State replacement and missing values treatment\n",
    "states = ['AL','AK','AZ','AR','CA','CO','CT','DC','DE','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME',\n",
    "          'MD','MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI',\n",
    "          'SC','SD','TN','TX','UT','VT','VA','WA','WV','WI','WY']\n",
    "\n",
    "train['state_cat'] = train.state.apply(lambda x: x if x in states else 'NOT US')\n",
    "train.loc[(train.state_cat != 'NOT US') & (train.state_cat != 'MI'),'state_cat'] = 'NOT MI'\n",
    "train.loc[train.state.isna(),'state_cat'] = 'MI' #Missing values most Frequent\n",
    "\n",
    "test['state_cat'] = test.state.apply(lambda x: x if x in states else 'NOT US')\n",
    "test.loc[(test.state_cat != 'NOT US') & (test.state_cat != 'MI'),'state_cat'] = 'NOT MI'\n",
    "test.loc[test.state.isna(),'state_cat'] = 'MI' #Missing values most Frequent\n",
    "#Fill in loc and lat using the average in the most frequent places\n",
    "#lat and lon is filled with rhe average of 50 most frequencies locations\n",
    "mtrain = train.groupby(['lon','lat']).compliance.agg(['count', 'sum', 'mean', 'std']).sort_values('count',ascending=False)\n",
    "lon = mtrain[mtrain['count']>50].index.get_level_values(0).tolist()\n",
    "lat = mtrain[mtrain['count']>50].index.get_level_values(1).tolist()\n",
    "lon = round(sum(lon) / float(len(lon)),6)\n",
    "lat = round(sum(lat) / float(len(lat)),6)\n",
    "train.loc[train.lon.isna(),'lon'] = lon #fill in missing values\n",
    "train.loc[train.lat.isna(),'lat'] = lat #fill in missing values\n",
    "mtest = test.groupby(['lon','lat']).agency_name.agg(['count']).sort_values('count',ascending=False)\n",
    "lon = mtest[mtest['count']>50].index.get_level_values(0).tolist()\n",
    "lat = mtest[mtest['count']>50].index.get_level_values(1).tolist()\n",
    "lon = round(sum(lon) / float(len(lon)),6)\n",
    "lat = round(sum(lat) / float(len(lat)),6)\n",
    "test.loc[test.lon.isna(),'lon'] = lon #fill in missing values\n",
    "test.loc[test.lat.isna(),'lat'] = lat #fill in missing values\n",
    "#X and y values\n",
    "ycol = ['compliance']\n",
    "xcol = ['state_cat','judgment_level','discount','disposition','agency_name','lat','lon']\n",
    "X = train[xcol]\n",
    "Xval = test[xcol]\n",
    "y = np.ravel(train[ycol].astype('int'))\n",
    "#dummy variables\n",
    "X2 = X.copy()\n",
    "X2['train'] = [1] * X.shape[0]\n",
    "#print(X.head())\n",
    "X2val = Xval.copy()\n",
    "X2val['train'] = [0] * Xval.shape[0]\n",
    "X_merged = pd.concat([X2, X2val], axis=0)\n",
    "X_merged = pd.get_dummies(X_merged)#.reset_index(drop=True)\n",
    "X = X_merged[X_merged.train == 1]\n",
    "Xval = X_merged[X_merged.train == 0]\n",
    "#model random forest\n",
    "model = RandomForestRegressor(random_state=8453, n_estimators=25, max_depth=15, max_features=10)\n",
    "model.fit(X, y)\n",
    "pred = model.predict(X)\n",
    "\n",
    "print('AUCROC for random forests')\n",
    "print(roc_auc_score(y,pred))\n",
    "\n",
    "m = pd.Series(model.predict(Xval), index=Xval.index, name='compliance', dtype='float32')\n",
    "print(m.shape)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
